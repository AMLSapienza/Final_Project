{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model import Resnet50FPN, CountRegressor, weights_normal_init, weights_xavier_init\n",
    "from utils_ltce import MAPS, Scales, Transform,TransformTrain,extract_features, visualize_output_and_save\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import exists,join\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torchvision.ops.boxes as bops\n",
    "from funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/LearningToCountEverything_new/data/'\n",
    "output_dir = \"./logsSave\"\n",
    "test_split = \"train\" #choices=[\"train\", \"test\", \"val\"]\n",
    "gpu = 0 \n",
    "learning_rate = 1e-5\n",
    "anno_file = data_path + 'annotation_FSC147_384.json'\n",
    "data_split_file = data_path + 'Train_Test_Val_FSC_147.json'\n",
    "im_dir = data_path + 'images_384_VarV2'\n",
    "gt_dir = data_path + 'gt_density_map_adaptive_384_VarV2'\n",
    "pre_trained_backbone = 'resnet' #choices=[resnet,wide_resnet,vgg16]\n",
    "regressor = CountRegressor(6, pool='mean')\n",
    "optimizer = optim.Adam(regressor.parameters(), lr = 1e-7)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "backbone_model = Resnet50FPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "\n",
    "#criterion = nn.MSELoss().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#backbone.cuda()\n",
    "#backbone.eval()\n",
    "\n",
    "weights_normal_init(regressor, dev=0.001)\n",
    "regressor.train()\n",
    "#regressor.cuda()\n",
    "optimizer = optim.Adam(regressor.parameters(), lr = learning_rate)\n",
    "\n",
    "with open(anno_file) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(data_split_file) as f:\n",
    "    data_split = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5l6', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "run_train_phase(epochs=3, backbone_model=backbone_model, regressor=regressor, yolo_model=model_yolo,\n",
    "                optimizer=optimizer, criterion=criterion, annotations=annotations, \n",
    "                data_train=data_split['train'], shuffle=False, data_val=data_split['val'], \n",
    "                num_img_train=5, num_img_val=5, yolo_flag=True, yolo_threshold=3, plot_flag=True, \n",
    "                save=False, im_dir=data_path+'images_384_VarV2', gt_dir=gt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "from model import Resnet50FPN, CountRegressor, weights_normal_init, weights_xavier_init\n",
    "from utils_ltce import MAPS, Scales, Transform,TransformTrain,extract_features, visualize_output_and_save\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import exists,join\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torchvision.ops.boxes as bops\n",
    "from funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/LearningToCountEverything_new/data/'\n",
    "output_dir = \"./logsSave\"\n",
    "test_split = \"train\" #choices=[\"train\", \"test\", \"val\"]\n",
    "gpu = 0 \n",
    "learning_rate = 1e-5\n",
    "anno_file = data_path + 'annotation_FSC147_384.json'\n",
    "data_split_file = data_path + 'Train_Test_Val_FSC_147.json'\n",
    "im_dir = data_path + 'images_384_VarV2'\n",
    "gt_dir = data_path + 'gt_density_map_adaptive_384_VarV2'\n",
    "pre_trained_backbone = 'resnet' #choices=[resnet,wide_resnet,vgg16]\n",
    "regressor = CountRegressor(6, pool='mean')\n",
    "optimizer = optim.Adam(regressor.parameters(), lr = 1e-7)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "backbone_model = Resnet50FPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "\n",
    "#criterion = nn.MSELoss().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#backbone.cuda()\n",
    "#backbone.eval()\n",
    "\n",
    "weights_normal_init(regressor, dev=0.001)\n",
    "regressor.train()\n",
    "#regressor.cuda()\n",
    "optimizer = optim.Adam(regressor.parameters(), lr = learning_rate)\n",
    "\n",
    "with open(anno_file) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(data_split_file) as f:\n",
    "    data_split = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5l6', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "test(data_split['test'][100:], num_img=50, backbone_model=backbone_model, regressor=regressor, \n",
    "     yolo_model=model_yolo, yolo_flag=False, yolo_threshold=3, annotations=annotations, \n",
    "     plot_flag=True, im_dir=data_path+'images_384_VarV2', use_gpu=False, \n",
    "     model_path='/content/drive/MyDrive/LearningToCountEverything_new/data/pretrainedModels/FamNet_Save1.pth',\n",
    "     adapt=False, gradient_steps=100, learning_rate=1e-7)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
